<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Implementing multiple nodes pytorch training - Jiangshan&#039;s Personal Website</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Jiangshan&#039;s Personal Website"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Jiangshan&#039;s Personal Website"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Training a model through multiple nodes and mulitple processes"><meta property="og:type" content="blog"><meta property="og:title" content="Implementing multiple nodes pytorch training"><meta property="og:url" content="http://gong208.github.io/2023/08/19/2023-08-19-multi-nodes-multi-processes/"><meta property="og:site_name" content="Jiangshan&#039;s Personal Website"><meta property="og:description" content="Training a model through multiple nodes and mulitple processes"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://gong208.github.io/img/assets/training_environment_2.png"><meta property="og:image" content="http://gong208.github.io/img/assets/WandB_config.png"><meta property="og:image" content="http://gong208.github.io/img/assets/occupied_gpus.png"><meta property="article:published_time" content="2023-08-20T03:29:15.000Z"><meta property="article:modified_time" content="2023-08-20T04:33:15.407Z"><meta property="article:author" content="Jiangshan Gong"><meta property="article:tag" content="MACHINELEARNING"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://gong208.github.io/img/assets/training_environment_2.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://gong208.github.io/2023/08/19/2023-08-19-multi-nodes-multi-processes/"},"headline":"Jiangshan Gong","image":["http://gong208.github.io/img/assets/training_environment_2.png","http://gong208.github.io/img/assets/WandB_config.png","http://gong208.github.io/img/assets/occupied_gpus.png"],"datePublished":"2023-08-20T03:29:15.000Z","dateModified":"2023-08-20T04:33:15.407Z","author":{"@type":"Person","name":"Jiangshan Gong"},"publisher":{"@type":"Organization","name":"Jiangshan's Personal Website","logo":{"@type":"ImageObject","url":"http://gong208.github.io/img/logo.svg"}},"description":"This is Jiangshan Gong&#39;s personal website"}</script><link rel="canonical" href="http://gong208.github.io/2023/08/19/2023-08-19-multi-nodes-multi-processes/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="Jiangshan&#039;s Personal Website" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/Blog">Blog</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/About">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-08-20T03:29:15.000Z" title="8/19/2023, 10:29:15 PM">2023-08-19</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-08-20T04:33:15.407Z" title="8/19/2023, 11:33:15 PM">2023-08-19</time></span><span class="level-item"><a class="link-muted" href="/categories/cs-learning/">cs_learning</a></span><span class="level-item">16 minutes read (About 2385 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">Implementing multiple nodes pytorch training</h1><div class="content"><p>Training a model through multiple nodes and mulitple processes</p>
<!-- more --> 
<h2 id="0-Introduction"><a href="#0-Introduction" class="headerlink" title="0. Introduction"></a>0. Introduction</h2><p>This blog passage focuses on implementing distributed data parallelism training among multiple nodes and multiple processes. Three methods, torch.distributed.launch, torchrun, and mpirun are covered. Using WandB to monitor the training process is also included.</p>
<h2 id="1-Resources"><a href="#1-Resources" class="headerlink" title="1. Resources"></a>1. Resources</h2><p>The model and the dataset are from this blog:<br><a target="_blank" rel="noopener" href="https://docs.google.com/document/d/1dSranGJOnn4WotvtogS6MzIdAE9Dda-NIyEFHflSyz8/edit?usp=sharing">https://docs.google.com/document/d/1dSranGJOnn4WotvtogS6MzIdAE9Dda-NIyEFHflSyz8/edit?usp=sharing</a><br>The training process refers to this passage:<br><a target="_blank" rel="noopener" href="https://lambdalabs.com/blog/multi-node-pytorch-distributed-training-guide">https://lambdalabs.com/blog/multi-node-pytorch-distributed-training-guide</a><br><a target="_blank" rel="noopener" href="https://github.com/LambdaLabsML/examples/tree/main/pytorch/distributed/resnet">https://github.com/LambdaLabsML/examples/tree/main/pytorch/distributed/resnet</a></p>
<h2 id="2-Training-environment"><a href="#2-Training-environment" class="headerlink" title="2. Training environment"></a>2. Training environment</h2><p><img src="/img/assets/training_environment_2.png" alt="The chart for the training equipments"></p>
<p>GPU driver: cuda-keyring_1.0-1<br>Virtual environment: conda 23.5.2<br>Requirements: python&#x3D;&#x3D;3.10.2<br>wandb&#x3D;&#x3D;0.15.8<br>tensorboard&#x3D;&#x3D;2.12.3<br>tensorboard-data-server&#x3D;&#x3D;0.7.1<br>datasets&#x3D;&#x3D;1.16.1</p>
<h2 id="3-Preparing-the-model-and-dataset"><a href="#3-Preparing-the-model-and-dataset" class="headerlink" title="3. Preparing the model and dataset"></a>3. Preparing the model and dataset</h2><p>We will deploy the model on two machines as illustrated above, each node is equipped with 8 GPUs. First of all, we have to make sure that the two nodes are connected through ssh. We can set up ip address using the following code on one machine:<br><code>~$ sudo ip address add 10.10.10.11/24 dev ens11f1</code><br>and on the other machine:<br><code>~$ sudo ip address add 10.10.10.11/24 dev ens11f1</code><br>You can use<br><code>~$ ip a</code><br>to check the ip address settings. Then we can use the ssh key to enable ssh connection without a password between the two nodes.<br>Download the Python script from <a target="_blank" rel="noopener" href="https://github.com/LambdaLabsML/examples/tree/main/pytorch/distributed/resnet">this repo</a> and the dataset as shown in <a target="_blank" rel="noopener" href="https://leimao.github.io/blog/PyTorch-Distributed-Training/">Mao Lei’s article</a> on each machine.<br>To view the information during the training process on WandB, we need to add some pieces of code that upload the parameters we want. First, we have to initiate WandB in the code, but only on the main process on the main node:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">if (LOCAL_RANK == 0 and WORLD_RANK==0):</span><br><span class="line">   wandb.init(project=project_name, config=argv)</span><br></pre></td></tr></table></figure>

<p>Make sure that WandB is initiated only on the main process in the main node and before enumerating the training epochs. <code>LOCAL_RANK</code> is the rank of the local GPUs, from 0 to 7 on each node. You can specify a random one as the main process. <code>WORLD_RANK</code> is the priority of the machines. The main node is ranked 0. In the code, <code>project=project_name</code> sets the project title displayed on WandB. <code>config</code> argument is optional. We can pass some hyperparameters about the model to it. For more information, check out <a target="_blank" rel="noopener" href="https://docs.wandb.ai/ref/python/init">this document about the .init() function</a>. </p>
<p><img src="/img/assets/WandB_config.png" alt="setting WandB terminal by codes"></p>
<p>Furthermore, we want to periodically upload parameters like loss rate and accuracy during training, so in the training loop, we can add</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if LOCAL_RANK == 0:</span><br><span class="line">    accuracy = evaluate(model=ddp_model, device=device, test_loader=test_loader)</span><br><span class="line">    torch.save(ddp_model.state_dict(), model_filepath)</span><br><span class="line">    if WORLD_RANK == 0:</span><br><span class="line">    wandb.log(&#123;&#x27;Epoch&#x27;: epoch,&#x27;accuracy&#x27;: accuracy&#125;)</span><br></pre></td></tr></table></figure>

<p>after <em>Line 171</em> and</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">if (LOCAL_RANK == 0 and WORLD_RANK==0):</span><br><span class="line">    wandb.log(&#123;&#x27;lr&#x27;: learning_rate, &#x27;samples&#x27;: count*batch_size, &#x27;loss/train&#x27;: loss.item()&#125;)</span><br></pre></td></tr></table></figure>

<p>after <em>Line 201</em>.<br><br>The complete code looks like：</p>
<figure class="highlight python"><figcaption><span>main.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data.distributed <span class="keyword">import</span> DistributedSampler</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> wandb</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> importlib</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;LOCAL_RANK&#x27;</span> <span class="keyword">in</span> os.environ:</span><br><span class="line">    <span class="comment"># Environment variables set by torch.distributed.launch or torchrun</span></span><br><span class="line">    LOCAL_RANK = <span class="built_in">int</span>(os.environ[<span class="string">&#x27;LOCAL_RANK&#x27;</span>])</span><br><span class="line">    WORLD_SIZE = <span class="built_in">int</span>(os.environ[<span class="string">&#x27;WORLD_SIZE&#x27;</span>])</span><br><span class="line">    WORLD_RANK = <span class="built_in">int</span>(os.environ[<span class="string">&#x27;RANK&#x27;</span>])</span><br><span class="line"><span class="keyword">elif</span> <span class="string">&#x27;OMPI_COMM_WORLD_LOCAL_RANK&#x27;</span> <span class="keyword">in</span> os.environ:</span><br><span class="line">    <span class="comment"># Environment variables set by mpirun</span></span><br><span class="line">    LOCAL_RANK = <span class="built_in">int</span>(os.environ[<span class="string">&#x27;OMPI_COMM_WORLD_LOCAL_RANK&#x27;</span>])</span><br><span class="line">    WORLD_SIZE = <span class="built_in">int</span>(os.environ[<span class="string">&#x27;OMPI_COMM_WORLD_SIZE&#x27;</span>])</span><br><span class="line">    WORLD_RANK = <span class="built_in">int</span>(os.environ[<span class="string">&#x27;OMPI_COMM_WORLD_RANK&#x27;</span>])</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">import</span> sys</span><br><span class="line">    sys.exit(<span class="string">&quot;Can&#x27;t find the evironment variables for local rank&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_random_seeds</span>(<span class="params">random_seed=<span class="number">0</span></span>):</span><br><span class="line"></span><br><span class="line">    torch.manual_seed(random_seed)</span><br><span class="line">    torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br><span class="line">    torch.backends.cudnn.benchmark = <span class="literal">False</span></span><br><span class="line">    np.random.seed(random_seed)</span><br><span class="line">    random.seed(random_seed)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">model, device, test_loader</span>):</span><br><span class="line"></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">            images, labels = data[<span class="number">0</span>].to(device), data[<span class="number">1</span>].to(device)</span><br><span class="line">            outputs = model(images)</span><br><span class="line">            _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">            total += labels.size(<span class="number">0</span>)</span><br><span class="line">            correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">    accuracy = correct / total</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> accuracy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    project_name = <span class="string">&#x27;DDP_model&#x27;</span></span><br><span class="line">    num_epochs_default = <span class="number">10000</span></span><br><span class="line">    batch_size_default = <span class="number">256</span></span><br><span class="line">    image_size_default = <span class="number">224</span></span><br><span class="line">    learning_rate_default = <span class="number">0.1</span></span><br><span class="line">    random_seed_default = <span class="number">0</span></span><br><span class="line">    model_dir_default = <span class="string">&quot;saved_models&quot;</span></span><br><span class="line">    model_filename_default = <span class="string">&quot;resnet_distributed.pth&quot;</span></span><br><span class="line">    steps_syn_default = <span class="number">20</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Each process runs on 1 GPU device specified by the local_rank argument.</span></span><br><span class="line">    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--local-rank&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&quot;Local rank. Necessary for using the torch.distributed.launch utility.&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--num_epochs&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&quot;Number of training epochs.&quot;</span>, default=num_epochs_default)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--batch_size&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&quot;Training batch size for one process.&quot;</span>, default=batch_size_default)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--image_size&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&quot;Size of input image.&quot;</span>, default=image_size_default)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--learning_rate&quot;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, <span class="built_in">help</span>=<span class="string">&quot;Learning rate.&quot;</span>, default=learning_rate_default)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--random_seed&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&quot;Random seed.&quot;</span>, default=random_seed_default)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--model_dir&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&quot;Directory for saving models.&quot;</span>, default=model_dir_default)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--model_filename&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&quot;Model filename.&quot;</span>, default=model_filename_default)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--resume&quot;</span>, action=<span class="string">&quot;store_true&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;Resume training from saved checkpoint.&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--backend&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&quot;Backend for distribted training.&quot;</span>, default=<span class="string">&#x27;nccl&#x27;</span>, choices=[<span class="string">&#x27;nccl&#x27;</span>, <span class="string">&#x27;gloo&#x27;</span>, <span class="string">&#x27;mpi&#x27;</span>])</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--arch&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&quot;Model architecture.&quot;</span>, default=<span class="string">&#x27;resnet50&#x27;</span>, choices=[<span class="string">&#x27;resnet50&#x27;</span>, <span class="string">&#x27;resnet18&#x27;</span>, <span class="string">&#x27;resnet101&#x27;</span>, <span class="string">&#x27;resnet152&#x27;</span>])</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--use_syn&quot;</span>, action=<span class="string">&quot;store_true&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;Use synthetic data&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--steps_syn&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&quot;Step per epoch for training with synthetic data&quot;</span>, default=steps_syn_default)</span><br><span class="line">    argv = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    local_rank = argv.local_rank</span><br><span class="line">    num_epochs = argv.num_epochs</span><br><span class="line">    batch_size = argv.batch_size</span><br><span class="line">    learning_rate = argv.learning_rate</span><br><span class="line">    random_seed = argv.random_seed</span><br><span class="line">    model_dir = argv.model_dir</span><br><span class="line">    model_filename = argv.model_filename</span><br><span class="line">    resume = argv.resume</span><br><span class="line">    backend = argv.backend</span><br><span class="line">    use_syn = argv.use_syn</span><br><span class="line">    w = argv.image_size</span><br><span class="line">    h = argv.image_size</span><br><span class="line">    c = <span class="number">3</span></span><br><span class="line">    steps_syn = argv.steps_syn</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create directories outside the PyTorch program</span></span><br><span class="line">    <span class="comment"># Do not create directory here because it is not multiprocess safe</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    if not os.path.exists(model_dir):</span></span><br><span class="line"><span class="string">        os.makedirs(model_dir)</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> (LOCAL_RANK == <span class="number">0</span> <span class="keyword">and</span> WORLD_RANK==<span class="number">0</span>):</span><br><span class="line">        wandb.init(project=project_name, config=argv)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    model_filepath = os.path.join(model_dir, model_filename)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># We need to use seeds to make sure that the models initialized in different processes are the same</span></span><br><span class="line">    set_random_seeds(random_seed=random_seed)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initializes the distributed backend which will take care of sychronizing nodes/GPUs</span></span><br><span class="line">    torch.distributed.init_process_group(backend=backend, rank=WORLD_RANK, world_size=WORLD_SIZE)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Encapsulate the model on the GPU assigned to the current process</span></span><br><span class="line">    model = <span class="built_in">getattr</span>(torchvision.models, argv.arch)(pretrained=<span class="literal">False</span>)</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(LOCAL_RANK))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    model = model.to(device)</span><br><span class="line">    ddp_model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[LOCAL_RANK], output_device=LOCAL_RANK)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># We only save the model who uses device &quot;cuda:0&quot;</span></span><br><span class="line">    <span class="comment"># To resume, the device for the saved model would also be &quot;cuda:0&quot;</span></span><br><span class="line">    <span class="keyword">if</span> resume == <span class="literal">True</span>:</span><br><span class="line">        map_location = &#123;<span class="string">&quot;cuda:0&quot;</span>: <span class="string">&quot;cuda:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(LOCAL_RANK)&#125;</span><br><span class="line">        ddp_model.load_state_dict(torch.load(model_filepath, map_location=map_location))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> use_syn:</span><br><span class="line">        <span class="comment"># Synthetic data</span></span><br><span class="line">        inputs_syn = torch.rand((batch_size, c, w, h)).to(device)</span><br><span class="line">        labels_syn = torch.zeros(batch_size, dtype=torch.int64).to(device)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># Prepare dataset and dataloader</span></span><br><span class="line">        transform = transforms.Compose([</span><br><span class="line">            transforms.RandomCrop(<span class="number">32</span>, padding=<span class="number">4</span>),</span><br><span class="line">            transforms.RandomHorizontalFlip(),</span><br><span class="line">            transforms.ToTensor(),</span><br><span class="line">            transforms.Normalize((<span class="number">0.4914</span>, <span class="number">0.4822</span>, <span class="number">0.4465</span>), (<span class="number">0.2023</span>, <span class="number">0.1994</span>, <span class="number">0.2010</span>)),</span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Data should be prefetched</span></span><br><span class="line">        <span class="comment"># Download should be set to be False, because it is not multiprocess safe</span></span><br><span class="line">        train_set = torchvision.datasets.CIFAR10(root=<span class="string">&quot;data&quot;</span>, train=<span class="literal">True</span>, download=<span class="literal">False</span>, transform=transform)</span><br><span class="line">        test_set = torchvision.datasets.CIFAR10(root=<span class="string">&quot;data&quot;</span>, train=<span class="literal">False</span>, download=<span class="literal">False</span>, transform=transform)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Restricts data loading to a subset of the dataset exclusive to the current process</span></span><br><span class="line">        train_sampler = DistributedSampler(dataset=train_set)</span><br><span class="line"></span><br><span class="line">        train_loader = DataLoader(dataset=train_set, batch_size=batch_size, sampler=train_sampler, num_workers=<span class="number">8</span>)</span><br><span class="line">        <span class="comment"># Test loader does not have to follow distributed sampling strategy</span></span><br><span class="line">        test_loader = DataLoader(dataset=test_set, batch_size=<span class="number">128</span>, shuffle=<span class="literal">False</span>, num_workers=<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">    criterion = nn.CrossEntropyLoss()</span><br><span class="line">    optimizer = optim.SGD(ddp_model.parameters(), lr=learning_rate, momentum=<span class="number">0.9</span>, weight_decay=<span class="number">1e-5</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Loop over the dataset multiple times</span></span><br><span class="line">    times = []</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Local Rank: &#123;&#125;, Epoch: &#123;&#125;, Training ...&quot;</span>.<span class="built_in">format</span>(LOCAL_RANK, epoch))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Save and evaluate model routinely</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> use_syn:</span><br><span class="line">            <span class="keyword">if</span> epoch % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">if</span> LOCAL_RANK == <span class="number">0</span>:</span><br><span class="line">                    accuracy = evaluate(model=ddp_model, device=device, test_loader=test_loader)</span><br><span class="line">                    torch.save(ddp_model.state_dict(), model_filepath)</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&quot;-&quot;</span> * <span class="number">75</span>)</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&quot;Epoch: &#123;&#125;, Accuracy: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(epoch, accuracy))</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&quot;-&quot;</span> * <span class="number">75</span>)</span><br><span class="line">                    <span class="keyword">if</span> WORLD_RANK == <span class="number">0</span>:</span><br><span class="line">                        wandb.log(&#123;<span class="string">&#x27;Epoch&#x27;</span>: epoch,<span class="string">&#x27;accuracy&#x27;</span>: accuracy&#125;)</span><br><span class="line"></span><br><span class="line">        ddp_model.train()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> use_syn:</span><br><span class="line">            start_epoch = time.time()</span><br><span class="line">            <span class="keyword">for</span> count <span class="keyword">in</span> <span class="built_in">range</span>(steps_syn):</span><br><span class="line">                optimizer.zero_grad()</span><br><span class="line">                outputs = ddp_model(inputs_syn)</span><br><span class="line">                loss = criterion(outputs, labels_syn)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># print(&quot;***&quot;*10)</span></span><br><span class="line">                <span class="comment"># print(loss.item())</span></span><br><span class="line">                <span class="comment"># print(type(loss.item()))</span></span><br><span class="line">                <span class="comment"># print(&quot;***&quot;*10)</span></span><br><span class="line">                <span class="keyword">if</span> (LOCAL_RANK == <span class="number">0</span> <span class="keyword">and</span> WORLD_RANK==<span class="number">0</span>):</span><br><span class="line">                    wandb.log(&#123;<span class="string">&#x27;lr&#x27;</span>: learning_rate, <span class="string">&#x27;samples&#x27;</span>: count*batch_size,</span><br><span class="line">                       <span class="string">&#x27;epoch&#x27;</span>: epoch, <span class="string">&#x27;loss/train&#x27;</span>: loss.item()&#125;)</span><br><span class="line">                loss.backward()</span><br><span class="line">                optimizer.step()</span><br><span class="line">            torch.cuda.synchronize()</span><br><span class="line">            end_epoch = time.time()</span><br><span class="line">            elapsed = end_epoch - start_epoch</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> epoch &gt; <span class="number">0</span>:</span><br><span class="line">                times.append(elapsed)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;num_steps_per_gpu: &#123;&#125;, avg_step_time: &#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(count, elapsed / count))</span><br><span class="line">                <span class="keyword">if</span> (LOCAL_RANK == <span class="number">0</span> <span class="keyword">and</span> WORLD_RANK==<span class="number">0</span>):</span><br><span class="line">                    wandb.log(&#123;<span class="string">&#x27;epoch&#x27;</span>: epoch, <span class="string">&#x27;num_steps_per_gpu&#x27;</span>: count, <span class="string">&#x27;avg_step_time&#x27;</span>: elapsed/count&#125;)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            train_loader.sampler.set_epoch(epoch)</span><br><span class="line">            start_epoch = time.time()</span><br><span class="line">            count = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> data <span class="keyword">in</span> train_loader:</span><br><span class="line">                inputs, labels = data[<span class="number">0</span>].to(device), data[<span class="number">1</span>].to(device)</span><br><span class="line">                optimizer.zero_grad()</span><br><span class="line">                outputs = ddp_model(inputs)</span><br><span class="line">                loss = criterion(outputs, labels)</span><br><span class="line">                loss.backward()</span><br><span class="line">                optimizer.step()</span><br><span class="line">                count += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> (LOCAL_RANK == <span class="number">0</span> <span class="keyword">and</span> WORLD_RANK==<span class="number">0</span>):</span><br><span class="line">                    wandb.log(&#123;<span class="string">&#x27;lr&#x27;</span>: learning_rate, <span class="string">&#x27;samples&#x27;</span>: count*batch_size,</span><br><span class="line">                       <span class="string">&#x27;epoch&#x27;</span>: epoch, <span class="string">&#x27;loss/train&#x27;</span>: loss.item()&#125;)</span><br><span class="line">            torch.cuda.synchronize()</span><br><span class="line">            end_epoch = time.time()</span><br><span class="line">            elapsed = end_epoch - start_epoch</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> epoch &gt; <span class="number">0</span>:</span><br><span class="line">                times.append(elapsed)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;num_steps_per_gpu: &#123;&#125;, avg_step_time: &#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(count, elapsed / count))</span><br><span class="line">                <span class="keyword">if</span> (LOCAL_RANK == <span class="number">0</span> <span class="keyword">and</span> WORLD_RANK==<span class="number">0</span>):</span><br><span class="line">                    wandb.log(&#123;<span class="string">&#x27;epoch&#x27;</span>: epoch, <span class="string">&#x27;num_steps_per_gpu&#x27;</span>: count, <span class="string">&#x27;avg_step_time&#x27;</span>: elapsed / count&#125;)</span><br><span class="line"></span><br><span class="line">    avg_time = <span class="built_in">sum</span>(times) / (num_epochs - <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Average epoch time: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(avg_time))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line"></span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<h2 id="4-Training-the-model-using-Distributed-Data-Parallelism"><a href="#4-Training-the-model-using-Distributed-Data-Parallelism" class="headerlink" title="4. Training the model using Distributed Data Parallelism"></a>4. Training the model using Distributed Data Parallelism</h2><ul>
<li><h4 id="Using-torch-distributed-launch"><a href="#Using-torch-distributed-launch" class="headerlink" title="Using torch.distributed.launch"></a><strong>Using torch.distributed.launch</strong></h4></li>
</ul>
<p>In order to use torch.distributed.launch, we need to run the following codes on two machines, respectively<br><br><strong>On the main node:</strong><br><code>python3 -m torch.distributed.launch --nproc_per_node=8 --nnodes=2 --node_rank=0 --master_addr=10.10.10.11 --master_port=1234 main.py --backend=nccl --use_syn --batch_size=256 --arch=resnet50</code><br><strong>On the worker node:</strong><br><code>python3 -m torch.distributed.launch --nproc_per_node=8 --nnodes=2 --node_rank=1 --master_addr=10.10.10.11 --master_port=1234 main.py --backend=nccl --use_syn --batch_size=256 --arch=resnet50</code><br><br>nproc_per_nod defines the number of workers on each node. It should equal to the number of GPUs on each node. nnodes defines the number of nodes.The only difference should be –node_rank. The argument  –use_syn means to use synthesized data, we can delete it if we use the dataset. </p>
<blockquote>
<p>Below are some problems you may encounter:</p>
</blockquote>
<ol>
<li><em>“main.py: error: unrecognized arguments: –local-rank&#x3D;7”</em><br>The log reports that the arguments for ranking all the local processes are unrecognized. This may be caused by a mistake in the Python script. We can solve this problem by changing “–local_rank” to “–local-rank” in the code “parser.add_argument(“–local_rank”)”.__</li>
<li><em>“torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.12<br>GiB (GPU 6; 44.35 GiB total capacity; 7.46 GiB already allocated; 5.80 GiB free; 7.48 GiB reserved in total by PyTorch) If reserved memory is &gt;&gt; allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF” on each GPU.</em><br>The error reports that the GPUs run out of memory. First, we may want to check if there are other running processes on the GPUs that occupies the memory.<br><code>~$ nvidia-smi</code><br><img src="/img/assets/occupied_gpus.png" alt="occupied gpus"><br>If there are irrelevant processses running on the GPUs like above, we can kill the processes by<br><code>~$ sudo killall python</code><br>Or terminate the processes using PID:<br><code>~$ sudo kill -9 [PID]</code><br>Sometimes when the previous attempt to train the model didn’t terminate properly, the terminal would report that the port is already in use when we are trying to start another attempt. In this case we can use<br><code>~$ sudo netstat -lnput</code><br>to check the process that occupies the port and terminate the process.<br>If the the GPUs still run out of memory even after clearing the processes, we have to consider adjusting the parameters like lowering the batch size and using a smaller model. Adjusting the argument to <code>–batch_size=256, –arch=resnet50</code> will be valid for the A40 GPUs in this case.</li>
</ol>
<ul>
<li><h4 id="Using-torchrun"><a href="#Using-torchrun" class="headerlink" title="Using torchrun"></a><strong>Using torchrun</strong></h4></li>
</ul>
<p>Torchrun works similarly to torch.distributed.launch:<br><strong>master:</strong><br><code>torchrun --nproc_per_node=8 --nnodes=2 --node_rank=0 --master_addr=10.10.10.11 --master_port=1234 main.py --backend=nccl --use_syn --batch_size=256 --arch=resnet50</code><br><strong>worker:</strong><br><code>torchrun --nproc_per_node=8 --nnodes=2 --node_rank=1 --master_addr=10.10.10.11 --master_port=1234 main.py --backend=nccl --use_syn --batch_size=256 --arch=resnet50</code></p>
<ul>
<li><h4 id="Using-mpirun"><a href="#Using-mpirun" class="headerlink" title="Using mpirun"></a><strong>Using mpirun</strong></h4></li>
</ul>
<p>Although the above methods work well for DDP on two nodes, they require run command on each node, making it inconvenient when there are more nodes. By contrast, We can launch the DDP training by only typing the command on the master node using mpirun. You can refer to the mpirun section in the passage <em><a target="_blank" rel="noopener" href="https://lambdalabs.com/blog/multi-node-pytorch-distributed-training-guide">Multi Node Pytorch Distributed Training Guide for People In a Hurry</a></em> for installation of OpenMPI and NCCL. Before training, we have to make sure that OpenMPI and NCCL are installed on all of the nodes, and they all use similar virtual environments. To start the DDP training using mpirun, we run the following command on the main node only:<br><code>mpirun -np 16 -H 10.10.10.11:8,10.10.10.12:8 -x MASTER_ADDR=10.10.10.11 -x MASTER_PORT=1234 -x PATH -bind-to none -map-by slot -mca pml ob1 -mca btl ^openib  python3 main.py --backend=nccl --use_syn --batch_size=256 --arch=resnet50</code><br>The PATH argument ensures that the script runs in the specified environment.</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>Implementing multiple nodes pytorch training</p><p><a href="http://gong208.github.io/2023/08/19/2023-08-19-multi-nodes-multi-processes/">http://gong208.github.io/2023/08/19/2023-08-19-multi-nodes-multi-processes/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Jiangshan Gong</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2023-08-19</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2023-08-19</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/MACHINELEARNING/">MACHINELEARNING</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2023/09/11/2023-09-11-ListADT/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">2023-09-11-ListADT</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2023/08/16/2023-08-16-single-node-multi-processes/"><span class="level-item">Implementing single node, multiple processes LLM training</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><script src="https://utteranc.es/client.js" repo="gong208/gong208.github.io" issue-term="pathname" label="comment" theme="github-light" crossorigin="anonymous" async></script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-10-17T21:47:58.000Z">2023-10-17</time></p><p class="title"><a href="/2023/10/17/2023-10-17-BinaryTree/">2023-10-17-BinaryTree</a></p><p class="categories"><a href="/categories/cs-learning/">cs_learning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-09-26T03:45:36.000Z">2023-09-25</time></p><p class="title"><a href="/2023/09/25/2023-09-25-StackAndQueue/">2023-09-25-StackAndQueue</a></p><p class="categories"><a href="/categories/cs-learning/">cs_learning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-09-11T14:47:24.000Z">2023-09-11</time></p><p class="title"><a href="/2023/09/11/2023-09-11-ListADT/">2023-09-11-ListADT</a></p><p class="categories"><a href="/categories/cs-learning/">cs_learning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-08-20T03:29:15.000Z">2023-08-19</time></p><p class="title"><a href="/2023/08/19/2023-08-19-multi-nodes-multi-processes/">Implementing multiple nodes pytorch training</a></p><p class="categories"><a href="/categories/cs-learning/">cs_learning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-08-16T19:00:57.000Z">2023-08-16</time></p><p class="title"><a href="/2023/08/16/2023-08-16-single-node-multi-processes/">Implementing single node, multiple processes LLM training</a></p><p class="categories"><a href="/categories/cs-learning/">cs_learning</a></p></div></article></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/cs-learning/"><span class="level-start"><span class="level-item">cs_learning</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/life/"><span class="level-start"><span class="level-item">life</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/my-dishes/"><span class="level-start"><span class="level-item">my_dishes</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/website-update/"><span class="level-start"><span class="level-item">website_update</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/DATA-STRUCTURE/"><span class="tag">DATA_STRUCTURE</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MACHINELEARNING/"><span class="tag">MACHINELEARNING</span><span class="tag">2</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="Jiangshan&#039;s Personal Website" height="28"></a><p class="is-size-7"><span>&copy; 2023 Jiangshan Gong</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2019</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/mhchem.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>